{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# suppress backend warnings\n",
    "%matplotlib tk\n",
    "# change the backend according to your OS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm\n",
    "\n",
    "Let's build an algorithm to\n",
    "\n",
    "- **Proximity detection**: Detect if you're too close or too far from the computer screen. This feature will **take care of your eyes**\n",
    "- **Posture detection**: Detect if you're in a bad posture (not sitting correctly while using the computer, or the computer is in a bad place)\n",
    "    + By checking if your face is within the camera range\n",
    "    + By checking how much area of the camera size and screen size is your face occupying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proximity detection\n",
    "\n",
    "This feature consists of 2 phases\n",
    "\n",
    "- Camera callibration\n",
    "- Distance calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera callibration\n",
    "\n",
    "This method of callibration is very simple and it is not very accurate.\n",
    "But it may serve good for the purposes of the application.\n",
    "\n",
    "The following image illustrates the basics of a pin-hole ideal camera (that's why this method is unnacurate, it does not take into account distortions or other stuff)\n",
    "\n",
    "![Camera model](resources/cam_model.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The calculated focal length $f$ may not be the **real** focal length. Remember, this algorithm is **not precise**.\n",
    "\n",
    "From the image above, the only variables we may know are:\n",
    "\n",
    "- $H_P$: Can be calculated by simply identifying the top and bottom of the projected rule\n",
    "- $H_R$ and $d$: We can ask the user to take some pictures of his/her face (and also ask its face height or simply take the average 23cm) at some specified distances (just in the callibration phase).\n",
    "\n",
    "With all that we can obtain the focal length by triangle similarity:\n",
    "\n",
    "$\n",
    "\\begin{equation}\n",
    "    \\frac{f}{H_P} = \\frac{d}{H_R}\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "$\n",
    "\\begin{equation}\n",
    "    f = \\frac{H_P d}{H_R}\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "But why do we want to compute the _focal length_ if we want to know the users' proximity/distance to the computer?\n",
    "\n",
    "Because once we know the $f$ parameter, we can simply solve the equation for $d$:\n",
    "\n",
    "$\n",
    "\\begin{equation}\n",
    "    d = f \\cdot \\frac{H_R}{H_P}\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "Or,\n",
    "\n",
    "$\n",
    "\\begin{equation}\n",
    "    f = d \\cdot \\frac{H_P}{H_R}\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "Overall:\n",
    "\n",
    "- Compute $f$ in the \"callibration\" phase.\n",
    "- Later on, Use $f$ to calculate the distance from the camera to the face of the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV will only detect the face starting from the eyebrows to the end of the lips.\n",
    "\n",
    "It will not detect the forehead, hair or chin, as show in the following figure\n",
    "\n",
    "![face.jpg](resources/face.jpg)\n",
    "\n",
    "The green rectangle encloses the \"face\" detected by OpenCV.\n",
    "\n",
    "The average height of the rectangle in real life is $12cm$, but we can ask the user to give its unique value to increase the precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load global stuff\n",
    "haar_cascade_face = cv2.CascadeClassifier(\"lbpcascade_frontalface_improved.xml\")\n",
    "face_height_cm = 12 # the user can change this value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just a util function to show and detect the user face\n",
    "# This will wait till the user presses a key and then return the measurements of the detected face\n",
    "def take_face_pic(video):\n",
    "    detected_face_rect = []\n",
    "\n",
    "    while True:\n",
    "        _, frame = video.read()\n",
    "\n",
    "        key_pressed = cv2.waitKey(1) & 0xFF\n",
    "        can_quit = False\n",
    "\n",
    "        # face detection\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces_rects = haar_cascade_face.detectMultiScale(gray_frame, scaleFactor=1.2, minNeighbors=5)\n",
    "        \n",
    "        if len(faces_rects) == 1:  # draw the rectangle\n",
    "            detected_face_rect = faces_rects[0]\n",
    "            (x, y, w, h) = faces_rects[0]\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            can_quit = True\n",
    "        elif len(faces_rects) > 1:\n",
    "            (frame_width, frame_height, _) = frame.shape\n",
    "            cv2.putText(frame, \"Multiple faces detected\", (0, frame_height // 2 - 50), cv2.FONT_HERSHEY_PLAIN, 4,\n",
    "                        (0, 0, 255))\n",
    "        elif len(faces_rects) == 0:\n",
    "            (frame_width, frame_height, _) = frame.shape\n",
    "            cv2.putText(frame, \"No face detected\", (0, frame_height // 2 - 50), cv2.FONT_HERSHEY_PLAIN, 4,\n",
    "                        (0, 0, 255))\n",
    "\n",
    "        cv2.imshow(\"original\", frame)\n",
    "\n",
    "        if can_quit and (key_pressed == ord('q') or key_pressed == ord('m')):  # q: quit, m: measure\n",
    "            break\n",
    "\n",
    "    return detected_face_rect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance calculation\n",
    "\n",
    "The following code is the implementation of the algorithm. In summary the code will do the following:\n",
    "\n",
    "- Take pictures at some specific distances to calculate the focal length $f = d \\cdot \\frac{H_P}{H_R}$. At each distance $f$ will be different so take the average value.\n",
    "- Repeat that process to get more values of $f$ (with more values, more precise the value will be and therefore more precise will the results)\n",
    "\n",
    "**Note 1**: This only works for values close to ~40cm. The real function is non-linear and the approximation is linear. But that is good because SpineWare will warn the user if he is too close (let's say < 50cm) to the screen\n",
    "\n",
    "**Note 2**: Just remember $f$ is not the real focal length, it is just the ideal focal length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_focal_length(video=None):\n",
    "    video_is_none = video is None\n",
    "    if video_is_none:\n",
    "        video = cv2.VideoCapture(0)\n",
    "\n",
    "    distances = [30, 40, 50, 60, 70]\n",
    "    face_heights_px = []\n",
    "\n",
    "    focal_lengths = []\n",
    "\n",
    "    for i in range(3):\n",
    "        for distance in distances:\n",
    "            print(\"\\n-----------\")\n",
    "            print(f\"Take a picture of your face at a distance of {distance}cm from the camera\")\n",
    "            print(\"Then, select the top and the bottom of your face\")\n",
    "\n",
    "            (x, y, w, face_height_px) = take_face_pic(video)\n",
    "\n",
    "            face_heights_px.append(face_height_px)\n",
    "\n",
    "        # compute an average value for the focal length\n",
    "        focal_length_values = [\n",
    "            face_height_px * distance / face_height_cm for distance, face_height_px in zip(distances, face_heights_px)\n",
    "        ]\n",
    "        focal_length = sum(focal_length_values) / len(focal_length_values)\n",
    "\n",
    "        focal_lengths.append(focal_length)\n",
    "\n",
    "    if video_is_none:\n",
    "        video.release()\n",
    "\n",
    "    return sum(focal_lengths) / len(focal_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the distance in real time\n",
    "def real_time_distance(video, focal_length):\n",
    "    while True:\n",
    "        _, frame = video.read()\n",
    "\n",
    "        key_pressed = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        # face detection\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces_rects = haar_cascade_face.detectMultiScale(gray_frame, scaleFactor=1.2, minNeighbors=5)\n",
    "        \n",
    "        if len(faces_rects) == 1:  # draw the rectangle\n",
    "            detected_face_rect = faces_rects[0]\n",
    "            (x, y, w, h) = faces_rects[0]\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            distance = focal_length * face_height_cm / h\n",
    "            cv2.putText(frame, str(distance // 1) + \"cm\", (20, 50), cv2.FONT_HERSHEY_PLAIN, 4, (255, 0, 0))\n",
    "        elif len(faces_rects) > 1:\n",
    "            (frame_width, frame_height, _) = frame.shape\n",
    "            cv2.putText(frame, \"Multiple faces detected\", (0, frame_height // 2 - 50), cv2.FONT_HERSHEY_PLAIN, 4,\n",
    "                        (0, 0, 255))\n",
    "        elif len(faces_rects) == 0:\n",
    "            (frame_width, frame_height, _) = frame.shape\n",
    "            cv2.putText(frame, \"No face detected\", (0, frame_height // 2 - 50), cv2.FONT_HERSHEY_PLAIN, 4,\n",
    "                        (0, 0, 255))\n",
    "\n",
    "        cv2.imshow(\"original\", frame)\n",
    "\n",
    "        if key_pressed == ord('q') or key_pressed == ord('m'):  # q: quit, m: measure\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Focal length is: 721\n"
     ]
    }
   ],
   "source": [
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "focal_length = 721#get_focal_length(video)\n",
    "print(f\"Focal length is: {focal_length}\")\n",
    "\n",
    "real_time_distance(video, 721)\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With $f$ calculated we can substitute values in the equation\n",
    "\n",
    "$\n",
    "\\begin{equation}\n",
    "    d = f \\frac{H_R}{H_P}\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "Just as an example, I'll fill in the values the computed focal length $f$ of my camera.\n",
    "\n",
    "$\n",
    "\\begin{equation}\n",
    "    d = 721 \\frac{H_R}{H_P}\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "We can plot the function to see how it looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_projected = np.linspace(50, 1080, 200) # from 50px to 1080px\n",
    "real_height = np.linspace(8, 16, 200) # from 8cm to 16cm\n",
    "\n",
    "X, Y = np.meshgrid(real_height, height_projected)\n",
    "\n",
    "Z = 721 * X / Y # Z = distance\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.contour3D(X, Y, Z, 200)\n",
    "ax.set_title(\"Distance as a function of object's real height(cm) and height projected(px)\")\n",
    "ax.set_xlabel(\"Real Height (cm)\")\n",
    "ax.set_ylabel(\"Height projected (px)\")\n",
    "ax.set_zlabel(\"Distance (cm)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the plot, everything makes sense, but from the plot we can also conclude that the algorithm may not be accurate for very far away distances, or very close distances.\n",
    "\n",
    "Since SpineWare does not need an extreme accuracy, it is ok to use this algorithm.\n",
    "\n",
    "Actually with the `real_time_distance` you can do some tests and see how the algorithm gives correct values for distances between 30cm and ~80cm, but not for values out of that range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posture detection\n",
    "\n",
    "Detect if you're in a bad posture (not sitting correctly while using the computer, or the computer is in a bad place)\n",
    "\n",
    "- By checking if your face is within some boundaries\n",
    "- By checking how much area of the camera size and screen size is your face occupying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if the face is within boundaries\n",
    "\n",
    "This is very simple, the following image illustrates the user having a **good posture**.\n",
    "\n",
    "The black rectangle illustrates the camera size, blue lines are the boundaries.\n",
    "\n",
    "![good posture](resources/posture_good.jpg)\n",
    "\n",
    "And the following image illustrates the user having a **bad posture**\n",
    "\n",
    "![good posture](resources/posture_bad.jpg)\n",
    "\n",
    "Because the user's face is not within the set boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these values should be between 0.55 and 0.99\n",
    "cam_width_acceptable_percentage = 0.9\n",
    "cam_height_acceptable_percentage = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "cam_width = round(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "cam_height = round(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# get the min and max coords\n",
    "min_acceptable_x, max_acceptable_x = round((1 - cam_width_acceptable_percentage) * cam_width), round(cam_width_acceptable_percentage * cam_width)\n",
    "min_acceptable_y, max_acceptable_y = round((1 - cam_height_acceptable_percentage) * cam_height), round(cam_height_acceptable_percentage * cam_height)\n",
    "\n",
    "while True:\n",
    "    _, frame = video.read()\n",
    "    \n",
    "    # draw the boundaries\n",
    "    cv2.line(frame, (min_acceptable_x, 0), (min_acceptable_x, cam_height), (255, 0, 0), 5)\n",
    "    cv2.line(frame, (max_acceptable_x, 0), (max_acceptable_x, cam_height), (255, 0, 0), 5)\n",
    "    cv2.line(frame, (0, min_acceptable_y), (cam_width, min_acceptable_y), (255, 0, 0), 5)\n",
    "    cv2.line(frame, (0, max_acceptable_y), (cam_width, max_acceptable_y), (255, 0, 0), 5)\n",
    "\n",
    "    key_pressed = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # face detection\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces_rects = haar_cascade_face.detectMultiScale(gray_frame, scaleFactor=1.2, minNeighbors=5)\n",
    "\n",
    "    if len(faces_rects) == 1:  # draw the rectangle\n",
    "        detected_face_rect = faces_rects[0]\n",
    "        (x, y, w, h) = faces_rects[0]\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        if x + w > max_acceptable_x or x < min_acceptable_x or y + h > max_acceptable_y or y < min_acceptable_y:\n",
    "            cv2.putText(frame, \"Face not in range\", (0, frame_height // 2 - 50), cv2.FONT_HERSHEY_PLAIN, 4,\n",
    "                    (50, 50, 255))\n",
    "    elif len(faces_rects) > 1:\n",
    "        (frame_width, frame_height, _) = frame.shape\n",
    "        cv2.putText(frame, \"Multiple faces detected\", (0, frame_height // 2 - 50), cv2.FONT_HERSHEY_PLAIN, 4,\n",
    "                    (0, 0, 255))\n",
    "    elif len(faces_rects) == 0:\n",
    "        (frame_width, frame_height, _) = frame.shape\n",
    "        cv2.putText(frame, \"No face detected\", (0, frame_height // 2 - 50), cv2.FONT_HERSHEY_PLAIN, 4,\n",
    "                    (0, 0, 255))\n",
    "\n",
    "    cv2.imshow(\"original\", frame)\n",
    "\n",
    "    if key_pressed == ord('q') or key_pressed == ord('m'):  # q: quit, m: measure\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is pretty simple and straightforward isn't it? I believe it requires no explaination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if the face is not receiving too much light from the screen\n",
    "\n",
    "![camera and screen sizes](resources/camera_screen_sizes.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$W_p$: Width projected in px\n",
    "\n",
    "$W_c$: Width of the camera in px\n",
    "\n",
    "$W_s$: Width of the screen in px\n",
    "\n",
    "From the illustration above we can calculate number of pixels of the screen occupied by the face along the $x$ axis $W_r$, and the number of pixels of the screen occupied by the face along the $y$ axis $H_r$.\n",
    "\n",
    "To obtain those values, we can simply find the ratio between the screen width and height between the projected width and height respectively $\\frac{W_s}{W_p}$ and $\\frac{H_s}{H_p}$.\n",
    "\n",
    "For example, if $\\frac{W_s}{W_p}$ is $1.6$ it means each px in the camera corresponds to $1.6$ pixels in the screen size. **note**: This is not a \"realistic\" correspondence between those measurements and it is useful just for this particular case.\n",
    "\n",
    "$H_r$ and $W_r$ are inside the boundaries\n",
    "\n",
    "$0 \\leq W_r \\leq W_s$\n",
    "\n",
    "$0 \\leq H_r \\leq H_s$\n",
    "\n",
    "With that we can obtain tell if the user is at a safe distance if $\\frac{W_r}{W_s} \\leq T_w$ and $\\frac{H_r}{H_s} \\leq T_h$\n",
    "\n",
    "Where\n",
    "\n",
    "- $T_h \\in (0, 1)$: Height threshold\n",
    "- $T_w \\in (0, 1)$: Width threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "cam_width = round(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "cam_height = round(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Obtain this values programatically\n",
    "screen_width = 1280\n",
    "screen_height = 720\n",
    "\n",
    "cam_screen_height_ratio = screen_height / cam_height\n",
    "cam_screen_width_ratio = screen_width / cam_width\n",
    "\n",
    "width_thresh = 0.4\n",
    "height_thresh = 0.4\n",
    "\n",
    "while True:\n",
    "    _, frame = video.read()\n",
    "\n",
    "    key_pressed = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # face detection\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces_rects = haar_cascade_face.detectMultiScale(gray_frame, scaleFactor=1.2, minNeighbors=5)\n",
    "\n",
    "    if len(faces_rects) == 1:  # draw the rectangle\n",
    "        detected_face_rect = faces_rects[0]\n",
    "        (x, y, w, h) = faces_rects[0]\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "        face_screen_width_ratio = w * cam_screen_width_ratio / screen_width\n",
    "        face_screen_height_ratio = h * cam_screen_height_ratio / screen_height\n",
    "        \n",
    "        if face_screen_width_ratio >= width_thresh or face_screen_height_ratio >= height_thresh:\n",
    "            text_color = (0, 0, 255)\n",
    "        else:\n",
    "            text_color = (255, 255, 255)\n",
    "        cv2.putText(frame, str(round(face_screen_width_ratio, 2)) + \"% w, \" + str(round(face_screen_height_ratio, 2)) + \"%, h\", (0, frame_height // 2 - 50), cv2.FONT_HERSHEY_PLAIN, 4, text_color)\n",
    "    elif len(faces_rects) > 1:\n",
    "        (frame_width, frame_height, _) = frame.shape\n",
    "        cv2.putText(frame, \"Multiple faces detected\", (0, frame_height // 2 - 50), cv2.FONT_HERSHEY_PLAIN, 4,\n",
    "                    (0, 0, 255))\n",
    "    elif len(faces_rects) == 0:\n",
    "        (frame_width, frame_height, _) = frame.shape\n",
    "        cv2.putText(frame, \"No face detected\", (0, frame_height // 2 - 50), cv2.FONT_HERSHEY_PLAIN, 4,\n",
    "                    (0, 0, 255))\n",
    "\n",
    "    cv2.imshow(\"original\", frame)\n",
    "\n",
    "    if key_pressed == ord('q') or key_pressed == ord('m'):  # q: quit, m: measure\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LaTeX area**\n",
    "\n",
    "$H_R$\n",
    "\n",
    "$H_P$\n",
    "\n",
    "$d$\n",
    "\n",
    "$f$\n",
    "\n",
    "$W_s$\n",
    "\n",
    "$W_c$\n",
    "\n",
    "$W_p$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": [
     "#\n",
     "# Copyright (c) 2020. Benjamín Antonio Velasco Guzmán\n",
     "# Author: Benjamín Antonio Velasco Guzmán <bg@benjaminguzman.dev>\n",
     "#\n",
     "# This program is free software: you can redistribute it and/or modify\n",
     "# it under the terms of the GNU General Public License as published by\n",
     "# the Free Software Foundation, either version 3 of the License, or\n",
     "# (at your option) any later version.\n",
     "#\n",
     "# This program is distributed in the hope that it will be useful,\n",
     "# but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
     "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
     "# GNU General Public License for more details.\n",
     "#\n",
     "# You should have received a copy of the GNU General Public License\n",
     "# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n"
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
